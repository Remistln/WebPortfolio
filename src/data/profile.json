{
    "basics": {
        "name": "Rémi Staelen",
        "label": "Étudiant en Master : Data Management in Biosciences",
        "image": "",
        "email": "remistpro@gmail.com",
        "phone": "06 28 47 65 89",
        "url": "",
        "summary": "Également titulaire d'un Bac+5 Chef de projet expert IA, avec trois ans d'alternance et deux stages dans le domaine de la data (Data Engineer, Data Analyst, Data Scientist). J'ai un intérêt marqué pour le monde de la data appliquée notamment à la biologie et je veux évoluer dans des environnements où ces compétences créent une valeur réelle.",
        "location": {
            "city": "Villeneuve-d'Ascq",
            "country": "France",
            "postalCode": "59650"
        },
        "profiles": []
    },
    "objective": {
        "title": "Recherche de Stage",
        "role": "Data Analyse / Data Engineering / Data Science en santé",
        "duration": "2 à 5 mois",
        "availability": "Dès le 30 mars 2026",
        "note": "Possibilité d'alternance en seconde année dès septembre 2026"
    },
    "education": [
        {
            "institution": "EDN - Université Catholique de Lille",
            "area": "Master Data Management in Biosciences",
            "studyType": "Master",
            "startDate": "2025",
            "endDate": "En cours",
            "description": "Bioinformatique, biostatistique, biologie moléculaire et cellulaire",
            "location": "Lille"
        },
        {
            "institution": "EPSI Lille",
            "area": "Mastère Chef de projet expert IA",
            "studyType": "Mastère",
            "startDate": "2023",
            "endDate": "2025",
            "location": "Lille"
        },
        {
            "institution": "EPSI Lille",
            "area": "Bachelor Concepteur et Développeur d'Applications",
            "studyType": "Bachelor",
            "startDate": "2022",
            "endDate": "2023",
            "location": "Lille"
        },
        {
            "institution": "EPSI Lille",
            "area": "BTS SIO — Solutions Logicielles et Applications Métiers",
            "studyType": "BTS",
            "startDate": "2020",
            "endDate": "2022",
            "location": "Lille"
        },
        {
            "institution": "Lycée Gustave Eiffel",
            "area": "Sciences de l'Ingénieur",
            "studyType": "BAC S",
            "startDate": "2020",
            "endDate": "2020",
            "description": "Section européenne anglais",
            "location": "Armentières"
        }
    ],
    "experience": [
        {
            "company": "Reconomia",
            "position": "Alternance Data Engineer / Analyst / Scientist",
            "startDate": "Septembre 2023",
            "endDate": "Août 2025",
            "highlights": [
                "Mise en place d'une architecture de données Data Lakehouse (Bronze/Silver/Gold) sur Microsoft Fabric",
                "Développement end-to-end d'un modèle IA de prédiction de pannes d'appareils électroménagers (XGBoost)",
                "Industrialisation et déploiement du modèle via une API sur Azure Machine Learning avec pipeline CI/CD",
                "Création de tableaux de bord de pilotage stratégique (KPIs) sur Power BI",
                "Automatisation des exports et rapports de tonnages trimestriels permettant la récupération de soutiens financiers auprès d'un éco-organisme",
                "Audit et nettoyage de données volumineuses (Big Data SAV) pour l'entraînement de modèles prédictifs"
            ]
        },
        {
            "company": "Daweiro",
            "position": "Alternance Data Engineer / Analyst",
            "startDate": "Juillet 2022",
            "endDate": "Septembre 2023",
            "highlights": [
                "Conception et déploiement d'une architecture Cloud Serverless sur AWS (Lambda, S3) pour la veille de tendances sociales",
                "Développement de pipelines d'ingestion automatisée de données et structuration en Data Lake requêtable via Amazon Athena",
                "Intégration de services d'Intelligence Artificielle AWS pour l'analyse sémantique et visuelle des contenus viraux",
                "Développement d'une application web Front-End en ReactJS pour la restitution et le filtrage des tendances",
                "Mise en place de l'Infrastructure as Code (IaC) via Terraform pour automatiser le déploiement des ressources Cloud",
                "Création de tableaux de bord décisionnels sur Amazon QuickSight pour le suivi des KPIs de viralité"
            ]
        },
        {
            "company": "PELOPS",
            "position": "Stage Développeur Fullstack & Ingénieur IA",
            "startDate": "Janvier 2022",
            "endDate": "Février 2022",
            "highlights": [
                "Développement Fullstack d'un module SIRH de suivi de candidats sur React.js et Symfony",
                "Conception d'une interface dynamique de gestion des processus de recrutement (Barres de progression, gestion d'états)",
                "Mise en place de formulaires interactifs liés à une base de données PostgreSQL via API Platform",
                "R&D en Intelligence Artificielle : Création d'un modèle de parsing de CV (NLP) avec Python et spaCy pour l'extraction automatique de compétences",
                "Gestion de projet collaborative avec Git et Trello"
            ]
        },
        {
            "company": "AllYouNeed",
            "position": "Stage Développeur Back-end",
            "startDate": "Mai 2021",
            "endDate": "Juin 2021",
            "highlights": [
                "Conception et développement d'un module d'authentification sécurisé (Login/Register) en PHP natif couplé à une base de données MySQL",
                "Sécurisation de l'application : implémentation du hachage de mots de passe et protection contre les injections SQL et failles XSS",
                "Refactoring et optimisation du code (Clean Code) via la séparation de la logique métier et de l'affichage pour faciliter la maintenance",
                "Mise en place des bonnes pratiques de développement : versioning avec Git/GitHub et respect du principe DRY",
                "Intégration d'API tierces (SMS/Microsoft) et initiation aux services Cloud (AWS) et au framework Symfony"
            ]
        }
    ],
    "skills": [
        {
            "category": "Data Science & IA",
            "subgroups": [
                {
                    "name": "Machine Learning",
                    "items": [
                        "Scikit-Learn",
                        "PyTorch",
                        "XGBoost",
                        "LightGBM",
                        "Optimisation Bayésienne"
                    ]
                },
                {
                    "name": "NLP",
                    "items": [
                        "SpaCy",
                        "NER"
                    ]
                },
                {
                    "name": "Analyse & Viz",
                    "items": [
                        "Python (Pandas, NumPy)",
                        "Power BI",
                        "QuickSight",
                        "Excel"
                    ]
                }
            ]
        },
        {
            "category": "Data Engineering & Cloud",
            "subgroups": [
                {
                    "name": "Cloud Platforms",
                    "items": [
                        "Mise en place d'unfrastructure cloud",
                        "AWS (Lambda, S3, Athena, RDS, VPC, IAM, SNS, SQS, CloudWatch)",
                        "Azure (ML, Foundry, Data Factory, Blob storage, Key Vault)",
                        "Microsoft Fabric (Dataflows, Power BI, Lakehouse)"
                    ]
                },
                {
                    "name": "Bases de Données",
                    "items": [
                        "SQL (PostgreSQL, MySQL)",
                        "Data Lake",
                        "Data Warehouse",
                        "Modélisation (Lambda/Kappa)"
                    ]
                },
                {
                    "name": "DevOps & Outils",
                    "items": [
                        "Terraform (IaC)",
                        "CI/CD",
                        "Git/GitHub (Actions)",
                        "Docker"
                    ]
                }
            ]
        },
        {
            "category": "Bio-Informatique",
            "subgroups": [
                {
                    "name": "Outils & Librairies",
                    "items": [
                        "BioPython",
                        "R"
                    ]
                },
                {
                    "name": "Domaines",
                    "items": [
                        "Génomique",
                        "Biostatistiques",
                        "Biologie Moléculaire"
                    ]
                }
            ]
        },
        {
            "category": "Soft Skills & Gestion",
            "subgroups": [
                {
                    "name": "Gestion de Projet",
                    "items": [
                        "Gestion des ressources",
                        "Analyse et Gestion des risques",
                        "Conduite du changement",
                        "Cahier des charges",
                        "Note de faisabilité",
                        "Note de besoin"
                    ]
                },
                {
                    "name": "Soft Skills",
                    "items": [
                        "Autonomie (apprentissage et execution)",
                        "Travail d'équipe (collaboration et communication)",
                        "Adaptabilité",
                        "Compréhension des besoins"
                    ]
                },
                {
                    "name": "Langues",
                    "items": [
                        "Français (Natif)",
                        "Anglais (C1)"
                    ]
                }
            ]
        }
    ],
    "interests": [
        {
            "name": "Batterie",
            "description": "8 ans (dont 3 ans en groupe)"
        },
        {
            "name": "Piano",
            "description": "1 an"
        },
        {
            "name": "Culture",
            "description": "Musées d’art et de sciences naturelles"
        },
        {
            "name": "Sport",
            "description": "Callisthénie"
        },
        {
            "name": "Formule 1",
            "description": "Passionné de sport automobile"
        }
    ],
    "projects": [
        {
            "title": "NeuroSift",
            "subtitle": "Pipeline de Classification d'IRM (End-to-End)",
            "image": "/images/projects/neurosift/app.png",
            "url": "https://github.com/Remistln/Neurosift",
            "description": "Développement d'une chaîne de traitement complète pour l'analyse d'imagerie médicale par Deep Learning. Simulation d'un pipeline d'aide au diagnostic.",
            "longDescription": "Dans le flux de travail radiologique quotidien, le tri manuel des séquences IRM (T1, T2, FLAIR) est une tâche chronophage et répétitive, pourtant indispensable avant tout diagnostic. NeuroSift vise à automatiser cette étape de 'triage' en amont, permettant aux praticiens de dédier leur expertise à l'analyse pathologique plutôt qu'à la gestion de données. L'objectif technique majeur était de concevoir une infrastructure 'bout-en-bout' réaliste, capable de simuler un environnement de production clinique. Le pipeline gère ainsi le cycle de vie complet de la donnée médicale : depuis l'ingestion automatisée de cohortes complexes (Glioblastomes) et le nettoyage de métadonnées DICOM, jusqu'au pré-traitement avancé normalisant les variabilités inter-machines, pour finalement servir des prédictions fiables via une interface radiologue ergonomique.",
            "tags": [
                "Deep Learning",
                "PyTorch",
                "Computer Vision",
                "Docker",
                "Medical Imaging"
            ],
            "steps": [
                {
                    "title": "1. Ingestion & Data Engineering",
                    "content": "Développement d'un pipeline d'extraction automatisé via l'API TCIA pour récupérer dynamiquement la cohorte UPENN-GBM. Le système parse ensuite l'arborescence DICOM native souvent chaotique pour structurer un Data Lake local propre et hiérarchisé (Patient > Étude > Série)."
                },
                {
                    "title": "2. Pre-processing Médical Avancé",
                    "content": "Traitement des données brutes inexploitables par les CNN classiques. J'ai implémenté une lecture 16-bit via Pydicom suivie d'une Normalisation Adaptative par Percentiles (1-99%) pour harmoniser les contrastes entre différentes machines IRM, avant la conversion finale en format standardisé 8-bit."
                },
                {
                    "title": "3. Modélisation (Deep Learning)",
                    "content": "Adoption d'une stratégie de Transfer Learning sur une architecture ResNet18 pour pallier la limitation du 'Small Data'. L'entraînement utilise l'optimiseur Adam et une Cross-Entropy Loss, validé par un 'Patient-Level Split' strict pour garantir que le modèle généralise sur de nouvelles anatomies sans mémorisation."
                },
                {
                    "title": "4. Infrastructure & MLOps",
                    "content": "Conception d'une architecture Micro-services 'Cloud-Ready' orchestrée par Docker Compose. Le système comprend un stockage d'images découplé via MinIO (S3-compatible), une base de données PostgreSQL pour les métadonnées et une interface Streamlit interactive pour le clinicien."
                }
            ],
            "challenges": [
                {
                    "title": "Le Biais du Contraste (Ambiguïté Sémantique)",
                    "content": "Une série T1 avec injection de Gadolinium classée incorrectement comme FLAIR (Confiance > 99%). Le modèle a appris l'hyper-intensité (blanche) comme signature du FLAIR, manquant le contexte du protocole d'acquisition."
                },
                {
                    "title": "Dérive de Distribution (Edge Case)",
                    "content": "Chute de performance (Confiance ~50%) sur les coupes orbitaires (base du crâne). Ces zones contiennent des structures (yeux, sinus) sous-représentées dans le dataset centré sur le cerveau, illustrant un cas d'Out-of-Distribution."
                }
            ],
            "stack": {
                "Framework": "PyTorch, Torchvision",
                "Computer Vision": "OpenCV, Pydicom",
                "Data Engineering": "Pandas, SQLAlchemy",
                "Infrastructure": "Docker, MinIO, PostgreSQL, MLflow",
                "Interface": "Streamlit"
            },
            "gallery": [
                {
                    "src": "/images/projects/neurosift/app.png",
                    "caption": "Interface NeuroSift : Analyse en temps réel d'une séquence T1"
                },
                {
                    "src": "/images/projects/neurosift/prediction.png",
                    "caption": "Visualisation de la prédiction et des régions d'intérêt"
                },
                {
                    "src": "/images/projects/neurosift/confusion_matrix.png",
                    "caption": "Matrice de confusion : Validation des performances sur le jeu de test"
                }
            ]
        },
        {
            "title": "BioSeq-Analyzer",
            "subtitle": "Suite d'Analyse Bioinformatique & Caractérisation Protéique",
            "image": "/images/projects/bioseq/dotplot.png",
            "url": "https://github.com/Remistln/BioSeq-Analyzer",
            "description": "Une plateforme interactive unifiant l'analyse de séquences multimodale. De l'alignement d'ADN pair-à-pair à la caractérisation structurelle de protéines via UniProt.",
            "longDescription": "L'analyse de séquences biologiques nécessite souvent de jongler entre des scripts en ligne de commande obscurs et des portails web fragmentés. BioSeq-Analyzer centralise ces flux de travail dans une application Streamlit robuste. Conçue pour faciliter l'exploration génomique et protéomique, l'outil permet aux chercheurs de valider statistiquement des alignements de séquences, de traduire dynamiquement des acides nucléiques en protéines (ORF finding), et de récupérer automatiquement des métadonnées fonctionnelles riches. L'architecture repose sur une intégration transparente des API majeures du domaine (NCBI Entrez, UniProt), transformant des données brutes FASTA en insights biologiques exploitables (structures 3D AlphaFold, littérature associée, domaines fonctionnels) en quelques clics.",
            "tags": [
                "Bioinformatics",
                "Streamlit",
                "Biopython",
                "API Integration",
                "Data Visualization"
            ],
            "steps": [
                {
                    "title": "1. Ingestion & Alignement Algorithmique",
                    "content": "Support du format standard FASTA avec parsing via Biopython. Implémentation d'algorithmes d'alignement globaux (Needleman-Wunsch) et locaux (Smith-Waterman) configurables. Ajout d'une couche de validation statistique par méthode de Monte-Carlo (50+ shuffles) pour distinguer les similitudes biologiques réelles du bruit aléatoire."
                },
                {
                    "title": "2. Visualisation Structurelle (Dotplots)",
                    "content": "Développement d'un moteur de visualisation matricielle (Dotplot) customizé avec Matplotlib. L'utilisateur peut filtrer le bruit visuel en ajustant dynamiquement la taille des fenêtres glissantes et les seuils de stringence (thresholds) pour révéler les répétitions, inversions et domaines conservés."
                },
                {
                    "title": "3. Traduction & Découverte d'ORF",
                    "content": "Algorithme de détection des cadres de lecture ouverts (ORF) sur 6 trames (Forward/Reverse). Le système identifie intelligemment le candidat protéique le plus probable (basé sur la longueur et les codons START/STOP) et permet la validation croisée via BLASTN sur les bases de données transcriptomiques RefSeq."
                },
                {
                    "title": "4. Enrichissement Fonctionnel (UniProt)",
                    "content": "Connexion en temps réel à l'API UniProtKB pour enrichir les séquences identifiées. L'application agrège et présente de manière structurée : la localisation subcellulaire, les pathologies associées, les domaines InterPro, et les liens vers les prédictions de structure AlphaFold."
                }
            ],
            "challenges": [
                {
                    "title": "Gestion d'État & Latence API",
                    "content": "L'interrogation synchrone de banques de données massives (NCBI BLAST) peut figer l'interface. J'ai dû implémenter une gestion fine des `session_state` Streamlit et des mécanismes de mise en cache pour préserver la fluidité de l'expérience utilisateur tout en gérant les timeouts et les limites de débit (rate limiting)."
                },
                {
                    "title": "Normalisation des Scores d'Alignement",
                    "content": "Un score d'alignement brut est difficilement interprétable sans contexte. L'intégration du test de randomisation (shuffling) a nécessité d'optimiser les boucles de calcul Numpy pour générer une distribution de référence à la volée sans impacter la réactivité de l'outil."
                }
            ],
            "stack": {
                "Frontend": "Streamlit",
                "Core Logic": "Biopython, Pandas",
                "Scientific Stack": "NumPy, Matplotlib",
                "External APIs": "NCBI Entrez (Bio.Entrez), UniProt REST",
                "Security": "SSL Context Management"
            },
            "gallery": [
                {
                    "src": "/images/projects/bioseq/dotplot.png",
                    "caption": "Visualisation matricielle (Dotplot) pour la détection de répétitions et d'homologies"
                },
                {
                    "src": "/images/projects/bioseq/alignment.png",
                    "caption": "Alignement de séquences optimal (Global/Local) avec matrice de substitution"
                },
                {
                    "src": "/images/projects/bioseq/most_likely_protein.png",
                    "caption": "Algorithme de détection d'ORF : Identification du candidat protéique le plus probable"
                },
                {
                    "src": "/images/projects/bioseq/prot_association.png",
                    "caption": "Identification de la protéine dans la base NCBI via BLAST"
                }
            ]
        },
        {
            "title": "Patient Performance Overview",
            "subtitle": "Dashboard Analytique Hospitalier & KPIs",
            "image": "/images/projects/patient_performance_overview/home.png",
            "description": "Tableau de bord décisionnel Power BI pour le pilotage de la performance hospitalière. Analyse multidimensionnelle des flux patients, de l'efficacité des services et de la satisfaction.",
            "longDescription": "Dans un contexte hospitalier sous tension, la visibilité sur les flux de patients est critique. Ce projet Power BI transforme des données brutes d'admission et de traitement en insights actionnables. Le rapport permet aux administrateurs de suivre en temps réel les indicateurs clés (Durée Moyenne de Séjour, Taux d'Occupation, Satisfaction) et de filtrer ces métriques par département ou par praticien. L'interface a été pensée pour une navigation intuitive, simulant une application web au sein même de l'outil de BI.",
            "tags": [
                "Power BI",
                "DAX",
                "Data Modeling",
                "UX Design",
                "Healthcare"
            ],
            "steps": [
                {
                    "title": "1. Modélisation en Étoile (Star Schema)",
                    "content": "Conception d'un modèle de données robuste : séparation des tables de faits (Admissions, Consultations) et des dimensions (Temps, Patients, Départements) pour garantir la rapidité des filtres croisés."
                },
                {
                    "title": "2. Mesures DAX Avancées",
                    "content": "Développement de mesures complexes en DAX pour le calcul de KPIs dynamiques : Time Intelligence (YTD, YoY), moyennes mobiles pour les tendances, et groupes de calcul pour le switch dynamique des métriques."
                },
                {
                    "title": "3. Design & Navigation",
                    "content": "Création d'une expérience utilisateur fluide avec des signets (Bookmarks) et des boutons de navigation. Utilisation de fonds personnalisés (Figma) pour sortir du look 'grille' standard de Power BI."
                },
                {
                    "title": "4. Analyse Parcours Patient",
                    "content": "Visualisation des goulots d'étranglement dans le parcours de soin via des graphiques de décomposition et des matrices de performance par service."
                }
            ],
            "stack": {
                "BI Tool": "Microsoft Power BI",
                "Languages": "DAX, M (Power Query)",
                "Data Source": "Excel / SQL",
                "Design": "Figma (Backgrounds)"
            },
            "gallery": [
                {
                    "src": "/images/projects/patient_performance_overview/home.png",
                    "caption": "Vue d'ensemble : KPIs macro et indicateurs de tendance"
                },
                {
                    "src": "/images/projects/patient_performance_overview/Home2.png",
                    "caption": "Vue Alternative : Indicateurs de performance secondaires"
                },
                {
                    "src": "/images/projects/patient_performance_overview/department.png",
                    "caption": "Analyse détaillée par Département (Flux & Efficacité)"
                },
                {
                    "src": "/images/projects/patient_performance_overview/patient.png",
                    "caption": "Focus Patient : Détail des admissions et historique"
                },
                {
                    "src": "/images/projects/patient_performance_overview/patient2.png",
                    "caption": "Détail Patient : Vue approfondie et historique clinique"
                },
                {
                    "src": "/images/projects/patient_performance_overview/performance.png",
                    "caption": "Matrice de Performance et Graphique de Décomposition"
                }
            ]
        }
    ]
}